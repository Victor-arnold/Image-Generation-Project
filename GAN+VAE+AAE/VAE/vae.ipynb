{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "from pytorch_fid import fid_score\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置超参数变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'cifar10_horse/train'\n",
    "sample_dir = 'Samples'\n",
    "fake_path = 'Reconstruction'\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "h_dim = 24 #潜在空间维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 设备配置\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, filenames, transform):\n",
    "        self.transform = transform\n",
    "        self.filenames = filenames\n",
    "        self.num = len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self.filenames[index]\n",
    "        img = torchvision.io.read_image(fname)\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "\n",
    "\n",
    "def get_dataset(dir):\n",
    "    fnames = glob.glob(os.path.join(dir, '*'))\n",
    "    tfm_ = [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ]\n",
    "    tfm = transforms.Compose(tfm_)\n",
    "    dataset = MyDataset(fnames, tfm)\n",
    "    return dataset\n",
    "\n",
    "train = get_dataset(data_path)\n",
    "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder\n",
    "\n",
    "Cov:3->16->64\n",
    "\n",
    "Fcnn:8\\*8\\*64->128->h_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "            \n",
    "        self.fc1 = nn.Linear(8 * 8 * 64, 128)\n",
    "        self.fc_bn1 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, h_dim)\n",
    "        self.fc_bn2 = nn.BatchNorm1d(h_dim)\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = x.view(-1, 8 * 8 * 64) #reshape\n",
    "\n",
    "        x = torch.nn.functional.relu(self.fc_bn1(self.fc1(x)))\n",
    "        x = torch.nn.functional.relu(self.fc_bn2(self.fc2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder\n",
    "\n",
    "与Encoder相反"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(h_dim, 128)\n",
    "        self.fc_bn1 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 64 * 8 * 8)\n",
    "        self.fc_bn2 = nn.BatchNorm1d(64 * 8 * 8)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x = torch.nn.functional.relu(self.fc_bn1(self.fc1(z)))\n",
    "        x = torch.nn.functional.relu(self.fc_bn2(self.fc2(x))).view(-1, 64, 8, 8)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = x.to(device)\n",
    "        \n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义VAE模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.enc_mu = nn.Linear(h_dim, h_dim)\n",
    "        self.enc_logvar = nn.Linear(h_dim, h_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = self.enc_mu(h), self.enc_logvar(h)\n",
    "        sigma = (logvar * 0.5).exp_()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        xhat = self.decoder(z)\n",
    "        return (mu, sigma), xhat\n",
    "    \n",
    "    def sample(self, n=1):\n",
    "        z = torch.randn(n, h_dim, dtype=torch.float)\n",
    "        z = z.to(device)\n",
    "        xhat = self.decoder(z)\n",
    "        xhat = xhat.detach()\n",
    "        return xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_loss(mu, logvar):\n",
    "    return -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "model = VAE(Encoder(), Decoder())\n",
    "model.to(device)  # 移动模型到cuda\n",
    "optimizer = optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512e2cf4bb6e4855b7271d50ed01e158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_epoch=0 loss=0.9066179910531411\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in tqdm.notebook.tqdm(range(num_epochs)):\n",
    "    total_loss = 0\n",
    "    for horse in (train_dl):\n",
    "        horse = horse.to(device)\n",
    "\n",
    "        h, xhat = model(horse)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(xhat, horse) + latent_loss(*h)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    total_loss /= len(train_dl)\n",
    "    print(f'i_epoch={epoch} loss={total_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重建并计算FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:15<00:00,  2.60it/s]\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fid score:175.05754957924023\n"
     ]
    }
   ],
   "source": [
    "model.eval(); #模型评估\n",
    "num = 0 #生成的马序号\n",
    "for img in train_dl:\n",
    "    img = img.to(device)\n",
    "    res = model(img)[1]\n",
    "    for i in range(len(img)):\n",
    "        image = torchvision.transforms.functional.to_pil_image(res[i])\n",
    "        image.save(os.path.join('Reconstruction' , '%d_horse.png'%num))\n",
    "        num += 1\n",
    "        if num==1000:break;\n",
    "    if num==1000:break;\n",
    "\n",
    "fid = fid_score.calculate_fid_given_paths([str(data_path), str(fake_path)], 128, torch.device(device), 2048)\n",
    "print('Fid score:'+str(fid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采样生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:11<00:00,  3.51it/s]\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fid score:286.7250259416106\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    image = torchvision.transforms.functional.to_pil_image(model.sample()[0])\n",
    "    image.save(os.path.join('Samples' , '%d_horse.png'%i))\n",
    "\n",
    "fid = fid_score.calculate_fid_given_paths([str(data_path), str(sample_dir)], 128, torch.device(device), 2048)\n",
    "print('Fid score:'+str(fid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f7b73ba524e88845b42eccf09a61b9b08c93ae28f46a34fd5f42c74d9518f42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
